{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoping\n",
    "\n",
    "### Project Goals\n",
    "\n",
    "This project is designed to utilize the skills I have learned and apply machine learning techniques to a data set. I went into this project blind and thus this project is meant to outline my method to understand and refine a dataset from scratch and derive insights from it. The initial guidance I recieved was to decide a research question at this point but without understanding the contents of a dataset, its limits and quirks, that would in my humble opinion be impossible to do.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "My Method is inspired by the one provided in: {insert book title here} (which is available neatly in appendix B pg. 497). \n",
    "\n",
    "However, against the apparent rigid and formulaic nature of the method provided therin I prefer to keep my processes iterative (recursive in a way) and dynamic. The format of this document may lead to you believe that I have gone about this project in clear steps and stages but this is mostly a function of the need for presentability and concistency. The process here is iterative and dynamic.\n",
    "    \n",
    "(Especially between the cleaning and exploratitory parts there is a lot of back and forth in understanding and refining the dataset to a state of usability I deem acceptable.)\n",
    "\n",
    "1. Preliminary Analysis - Quick look at the dataset, preparation for test integrity and initial assessment of usefullness for the task ahead.\n",
    "2. Cleaning Data - serves primarily as a cleaning of the dataset but also as an initial analysis of each of the attributes. (This is exhaustive but also good practice in refining a dataset)\n",
    "3. Exploratory Analysis - Explore the datasets relationships and patterns incl. its noisiness, distribution and possible usefulness for the task ahead. (Note: this is done after the clean so as to not have the exploration biased by missing values, incorrect inputs e.tc )\n",
    "4. Framing - Decide and Assess an objective, think about what a solution would look like, how I would measure its performance and list assumptions.\n",
    "5. Experimentation and refienment - testing models, validating them and evaluating them.\n",
    "6. Presentation and Interpretation - show the results and interpet them in the context of the research question\n",
    "\n",
    "The primary research question that I have detemerined to be answered is that of whether\n",
    "\n",
    "### Assumptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python Modules\n",
    "First things first is to import the python modules I will be using for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "The first step I take is to load the provided data into a pandas DataFrame object so that it can be efficiently explored and manipulated in python.\n",
    "\n",
    "This involves the file `profiles.csv` being loaded into the `profiles` DataFrame. It is subsequently displayed for examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education  \\\n",
       "0      working on college/university   \n",
       "1              working on space camp   \n",
       "2     graduated from masters program   \n",
       "3      working on college/university   \n",
       "4  graduated from college/university   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\nhttp://bag...   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  the way i look. i am a six foot half asian, ha...  ...   \n",
       "1                                                NaN  ...   \n",
       "2  my large jaw and large glasses are the physica...  ...   \n",
       "3                  socially awkward but i do my best  ...   \n",
       "4            i smile a lot and my inquisitive nature  ...   \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "2        san francisco, california   \n",
       "3             berkeley, california   \n",
       "4        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "3                           english, german (poorly)     single  \n",
       "4                                            english     single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('profiles.csv', encoding = 'utf-8')\n",
    "df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight away I can tell there is no point in looking at the value counts of the `essay{number}` columns as they are more likely infinitely variable, will not have any repeating entries and this project doesn't involve NLP. Let's drop them immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = [f'essay{i}' for i in range(0, 10, 1)]\n",
    "df.drop(essays, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the Data Characteristics\n",
    "\n",
    "First it is advisable to look at the data types and columns presented to us in the data and determine how much data we are dealing with exactly.\n",
    "\n",
    "Doing a few simple calls to variables of the dataframe reveals that our dating profiles data consists of 59,946 rows (or users) and 31 attributes/columns.\n",
    "\n",
    "Each column's name is sort of self descriptive of what sort of information is expected therein so there is no need to elaborate them here, any nuance within them will be explained in further parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   body_type    54650 non-null  object \n",
      " 2   diet         35551 non-null  object \n",
      " 3   drinks       56961 non-null  object \n",
      " 4   drugs        45866 non-null  object \n",
      " 5   education    53318 non-null  object \n",
      " 6   ethnicity    54266 non-null  object \n",
      " 7   height       59943 non-null  float64\n",
      " 8   income       59946 non-null  int64  \n",
      " 9   job          51748 non-null  object \n",
      " 10  last_online  59946 non-null  object \n",
      " 11  location     59946 non-null  object \n",
      " 12  offspring    24385 non-null  object \n",
      " 13  orientation  59946 non-null  object \n",
      " 14  pets         40025 non-null  object \n",
      " 15  religion     39720 non-null  object \n",
      " 16  sex          59946 non-null  object \n",
      " 17  sign         48890 non-null  object \n",
      " 18  smokes       54434 non-null  object \n",
      " 19  speaks       59896 non-null  object \n",
      " 20  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 9.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include = 'object').columns:\n",
    "    df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Asside A Sample Test Set\n",
    "\n",
    "This ensures we keep data snooping bias out of our project! The dataset is quite large so I am assuming there is no need for stratefied sampling. The following code ensures that we can reuse our split despite modification or removal of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Uncomment the following code to create new csv with identifiers###\n",
    "#from reproducable_split import add_identifiers\n",
    "#add_identifiers(df, create_new = True, new_name = \"profiles_identifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment the following code to create a new split map ###\n",
    "#from reproducable_split import create_splitmap\n",
    "#profiles = pd.read_csv(\"profiles_identifiers.csv\")\n",
    "#create_splitmap(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating a small function that creates our train set `working` which we will use to do our analysis of the dataset while keeping our future training set out of sight as to avoid bias. \n",
    "\n",
    "There are obviously some points of analysis that we can use with our entire set and won't compromise the integreity of our tests as you will see later. \n",
    "\n",
    "All modifications will be done to the profiles dataset. Then we can recreate the working dataset to continue looking at our variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we bring in the profiles with identifiers I have created earlier\n",
    "profiles = pd.read_csv(\"profiles_identifiers.csv\")\n",
    "\n",
    "#As well as the split map\n",
    "split_map = pd.read_csv(\"split_mapping.csv\")\n",
    "\n",
    "profiles = profiles.merge(split_map, on = \"unique_id\", how = \"inner\")\n",
    "\n",
    "def create_working(df, split_map):\n",
    "    train_df = df[df[\"which_set\"] == \"train\"]\n",
    "    working = train_df.copy()\n",
    "    return working\n",
    "\n",
    "def create_holding(df, split_map):\n",
    "    test_df = df[df[\"which_set\"] == \"test\"]\n",
    "    holding = test_df.copy()\n",
    "    return holding\n",
    "\n",
    "\n",
    "working = create_working(profiles, split_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "First up is to clean the data and make sure it is suitable for use. My cleaning process for a single dataset consists of five steps:\n",
    "\n",
    "\n",
    "1. Handling duplicate rows\n",
    "2. Simplifying and standardizng attributes \n",
    "3. Handling missing values\n",
    "4. Handling outliers + noise\n",
    "5. Handling inconsitent attributes \n",
    "\n",
    "## Handling Duplicates\n",
    "\n",
    "Luckily our dataset does not have any duplicate entries so we can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are all clear on duplicate entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying attributes\n",
    "\n",
    "This section's general aim is to simplify primarily categorical attributes that have way too many different catagories and potentially give NA entries actual values.\n",
    "\n",
    "From a brief look at the number of unique values and a little reference back up to our dtypes (plus a little behind the scenes checks on value counts) we can see that a few columns are up for a little simplification, these being:\n",
    "\n",
    "1. education\n",
    "2. ethnicity\n",
    "3. speaks\n",
    "4. pets\n",
    "5. religion\n",
    "6. sign\n",
    "7. speaks\n",
    "8. diet\n",
    "9. offspring\n",
    "\n",
    "Additionally we want to sort out the corrupted strings in:\n",
    "1. offspring\n",
    "2. sign\n",
    "\n",
    "#NOTE INCOME IS FUNNY AS IT MIGHT AS WELL BE CATEGORICAL AS IT IS A SET OF NUMERICAL BRACKETS (ie. 20000, 100000, 80000) that people are put under."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "graduated from college/university    21574\n",
       "graduated from masters program        8095\n",
       "NaN                                   5953\n",
       "working on college/university         5147\n",
       "working on masters program            1529\n",
       "graduated from two-year college       1374\n",
       "graduated from high school            1276\n",
       "graduated from ph.d program           1138\n",
       "graduated from law school             1003\n",
       "working on two-year college            944\n",
       "dropped out of college/university      888\n",
       "working on ph.d program                882\n",
       "college/university                     725\n",
       "graduated from space camp              599\n",
       "dropped out of space camp              470\n",
       "graduated from med school              412\n",
       "working on space camp                  396\n",
       "working on law school                  250\n",
       "two-year college                       197\n",
       "working on med school                  190\n",
       "dropped out of two-year college        167\n",
       "dropped out of masters program         125\n",
       "masters program                        121\n",
       "dropped out of ph.d program            116\n",
       "dropped out of high school              95\n",
       "high school                             83\n",
       "working on high school                  80\n",
       "space camp                              48\n",
       "ph.d program                            21\n",
       "law school                              16\n",
       "dropped out of law school               15\n",
       "dropped out of med school               11\n",
       "med school                              11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.education.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at education we can see that it has way too many possible categories but it essentially boils down to two changing points of information (leaving out NaN of course).\n",
    "\n",
    "1. Status: Has the person graduated, learning or dropped out of their educational program.\n",
    "2. Program: The particular educational program in question\n",
    "\n",
    "This is quite easy to simplify, we can just split this single column with a high amount of values into two columns with much less variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a little helper function to assist us in seperating out these two pieces of information.\n",
    "#it takes the list of values I have found for each point of information in the education column\n",
    "#and checks if each value is in the string and if so returns that value.\n",
    "#Please note that the string1 argument is to adress a particular flaw where the user does not have a status.\n",
    "#It is my assupmtion that whoever does not have a status is graduated.\n",
    "#Function also persists NA values\n",
    "def replacer(lst, x, string1 = None):\n",
    "    if isinstance(x, str):\n",
    "        for l in lst:\n",
    "            if l.lower() in x.lower():\n",
    "                return l\n",
    "        if isinstance(string1, str):\n",
    "            return string1\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education_level\n",
      "college/university    28334\n",
      "masters                9870\n",
      "<NA>                   5953\n",
      "two-year college       2682\n",
      "ph.d                   2157\n",
      "high school            1534\n",
      "space camp             1513\n",
      "law school             1284\n",
      "med school              624\n",
      "Name: count, dtype: int64\n",
      "education_status\n",
      "graduated      36693\n",
      "working on      9418\n",
      "<NA>            5953\n",
      "dropped out     1887\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#create new column for education level\n",
    "edu = ['space camp', 'high school', 'two-year college', 'college/university', 'law school', 'med school', 'masters', 'ph.d']\n",
    "profiles['education_level'] = profiles['education'].apply(lambda x: replacer(edu, x))\n",
    "\n",
    "#create new column for education status \n",
    "edu = ['dropped out', 'working on', 'graduated']\n",
    "profiles['education_status'] = profiles['education'].apply(lambda x: replacer(edu, x, 'graduated'))\n",
    "\n",
    "working = create_working(profiles, split_map)\n",
    "print(working.education_level.value_counts(dropna = False))\n",
    "print(working.education_status.value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying Ethnicity\n",
    "\n",
    "I would like to note that I have come back to this attribute after reviewing my work and would like to clarify that when I address this particular attribute that I have no intention of using it in my analysis. This is becauce while this attribute is named \"ethnicity\", based on the labels within it, it is more akin to race. While this attribute could be potentially useful for machine learning some sort of relation with a person's percieved race I do not percieve it necessary or useful for an analysis and personally do not believe it would hold any value.\n",
    "\n",
    "Regardless I will display how I attempted to simplify the many categories of this attribute. Take its methodology and assumptions as you will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                   white\n",
       "2                     NaN\n",
       "3                   white\n",
       "4     asian, black, other\n",
       "6            white, other\n",
       "8                   white\n",
       "9                   white\n",
       "10                  white\n",
       "11                  white\n",
       "12                  white\n",
       "Name: ethnicity, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.ethnicity.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity\n",
       "white                                                                     29517\n",
       "asian                                                                      5552\n",
       "NaN                                                                        5118\n",
       "hispanic / latin                                                           2542\n",
       "black                                                                      1799\n",
       "                                                                          ...  \n",
       "asian, middle eastern, native american, pacific islander, white, other        1\n",
       "middle eastern, black, other                                                  1\n",
       "asian, middle eastern, black, pacific islander, hispanic / latin              1\n",
       "asian, black, pacific islander, white, other                                  1\n",
       "asian, black, indian                                                          1\n",
       "Name: count, Length: 210, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.ethnicity.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of first things we can notice about our ethnicity values is that there are a lot of people who are an ethnicity onto themselves, which might be interesting for anthropologists but unfortunately for us is not very good for ML models as they aren't very generalizable.\n",
    "\n",
    "Let's make things a bit simpler and of course this involves an assumption:\n",
    "\n",
    "1. If a person has multiple ethnicities (more than 3) they can be assumed to be part of a group (mixed) and that this group can be generalized to be the same and the patterns in the data are still maintained. (FLAWED?)\n",
    "\n",
    "The rest will be simplified by splitting people into their primary and secondary ethnicity (the majority of the dataset adheres to this cleanly) while people with multiple ethnicities will be put down as mixed for both ethnicity 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a little helper function made to cut down any multiple ethnicity entires into something more palatable.\n",
    "#Comments explain what it does for this particualr attribute.\n",
    "def long_handler(x, string1):\n",
    "    if isinstance(x, str):\n",
    "        x = x.split(\",\")\n",
    "\n",
    "        if len(x) < 3:\n",
    "            if len(x) == 1:\n",
    "                return(x.pop()) # if someone is just 1 ethnicity than return that one ethnicity\n",
    "            else:\n",
    "                return x # if someone is two ethnicities than just send those back too\n",
    "        else:\n",
    "            return string1 #if the number of ethnicities a person is, is greater than 3 then return them as mixed\n",
    "    \n",
    "    else:\n",
    "        return pd.NA #if the entry is N/A or somehow not a string then return N/A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity_1</th>\n",
       "      <th>ethnicity_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixed</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>white</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ethnicity_1 ethnicity_2\n",
       "1        white       white\n",
       "2         <NA>        <NA>\n",
       "3        white       white\n",
       "4        mixed       mixed\n",
       "6        white       other\n",
       "8        white       white\n",
       "9        white       white\n",
       "10       white       white\n",
       "11       white       white\n",
       "12       white       white"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.ethnicity = profiles.ethnicity.apply(lambda x: long_handler(x, 'mixed'))\n",
    "profiles[\"ethnicity_1\"] = profiles.ethnicity.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "profiles[\"ethnicity_2\"] = profiles.ethnicity.apply(lambda x: x[1] if isinstance(x, list) else x)\n",
    "\n",
    "working = create_working(profiles, split_map)\n",
    "working[[\"ethnicity_1\", \"ethnicity_2\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.drop(columns = [\"ethnicity_1\", \"ethnicity_2\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying Pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pets\n",
       "NaN                                17889\n",
       "likes dogs and likes cats          13375\n",
       "likes dogs                          6512\n",
       "likes dogs and has cats             3855\n",
       "has dogs                            3753\n",
       "has dogs and likes cats             2084\n",
       "likes dogs and dislikes cats        1844\n",
       "has dogs and has cats               1334\n",
       "has cats                            1257\n",
       "likes cats                           941\n",
       "has dogs and dislikes cats           496\n",
       "dislikes dogs and likes cats         215\n",
       "dislikes dogs and dislikes cats      172\n",
       "dislikes cats                        110\n",
       "dislikes dogs and has cats            75\n",
       "dislikes dogs                         39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.pets.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pets` column has a lot of different categories but can be easily simplified into two columns where cat and dog dispositions are represented seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another little helper function made to seprate our pet lovers opinions on cats and dogs clearly.\n",
    "def pet_sentiment(x, pet: str):\n",
    "\n",
    "    if isinstance(x, str):\n",
    "        if \" and \" in x:\n",
    "            result = x.split(\" and \")\n",
    "            if pet == 'dog':\n",
    "                result1 = result[0].removesuffix(\" dogs\")\n",
    "                return result1\n",
    "            elif pet == 'cat':\n",
    "                result2 = result[1].removesuffix(\" cats\")\n",
    "                return result2\n",
    "    \n",
    "        elif  pet == 'dog':\n",
    "            if \"dogs\" in x:\n",
    "                result1 = x.removesuffix(\" dogs\")\n",
    "                return result1\n",
    "            else:\n",
    "                return 'no opinion'\n",
    "        elif pet == 'cat':\n",
    "            if \"cats\" in x:\n",
    "                result2 = x.removesuffix(\" cats\")\n",
    "                return result2\n",
    "            else:\n",
    "                return 'no opinion'\n",
    "    else:   \n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>likes</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>likes</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>likes</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>has</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>has</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cats        dogs\n",
       "1   likes       likes\n",
       "2     has  no opinion\n",
       "3   likes  no opinion\n",
       "4   likes       likes\n",
       "6   likes       likes\n",
       "8   likes       likes\n",
       "9   likes       likes\n",
       "10   <NA>        <NA>\n",
       "11  likes  no opinion\n",
       "12   <NA>        <NA>\n",
       "13  likes         has\n",
       "14    has       likes\n",
       "15    has       likes\n",
       "16  likes       likes\n",
       "17   <NA>        <NA>\n",
       "18  likes       likes\n",
       "19  likes       likes\n",
       "21  likes       likes\n",
       "22  likes       likes\n",
       "23  likes       likes"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles['dogs'] = profiles.pets.apply(lambda x: pet_sentiment(x, 'dog'))\n",
    "profiles['cats'] = profiles.pets.apply(lambda x: pet_sentiment(x, 'cat'))\n",
    "\n",
    "working = create_working(profiles, split_map)\n",
    "working[['cats', 'dogs']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `religion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion\n",
       "NaN                                           18188\n",
       "agnosticism                                    2458\n",
       "other                                          2440\n",
       "agnosticism but not too serious about it       2363\n",
       "agnosticism and laughing about it              2260\n",
       "catholicism but not too serious about it       2100\n",
       "atheism                                        1956\n",
       "other and laughing about it                    1898\n",
       "atheism and laughing about it                  1874\n",
       "christianity                                   1749\n",
       "christianity but not too serious about it      1743\n",
       "other but not too serious about it             1398\n",
       "judaism but not too serious about it           1372\n",
       "atheism but not too serious about it           1182\n",
       "catholicism                                     948\n",
       "christianity and somewhat serious about it      820\n",
       "other and somewhat serious about it             761\n",
       "atheism and somewhat serious about it           754\n",
       "catholicism and laughing about it               671\n",
       "judaism and laughing about it                   621\n",
       "buddhism but not too serious about it           599\n",
       "agnosticism and somewhat serious about it       574\n",
       "judaism                                         542\n",
       "christianity and very serious about it          522\n",
       "atheism and very serious about it               508\n",
       "catholicism and somewhat serious about it       484\n",
       "other and very serious about it                 479\n",
       "buddhism and laughing about it                  422\n",
       "buddhism                                        363\n",
       "christianity and laughing about it              332\n",
       "buddhism and somewhat serious about it          332\n",
       "agnosticism and very serious about it           287\n",
       "judaism and somewhat serious about it           241\n",
       "hinduism but not too serious about it           200\n",
       "hinduism                                         99\n",
       "catholicism and very serious about it            98\n",
       "buddhism and very serious about it               63\n",
       "hinduism and somewhat serious about it           52\n",
       "islam                                            43\n",
       "hinduism and laughing about it                   40\n",
       "islam but not too serious about it               35\n",
       "judaism and very serious about it                22\n",
       "islam and somewhat serious about it              18\n",
       "islam and laughing about it                      16\n",
       "hinduism and very serious about it               14\n",
       "islam and very serious about it                  10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.religion.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another attribute with a lot of N/A but looking at the actual data here we can clearly see that this attribute containts two specific parts of a persons religion. These being\n",
    "1. Their actual religion\n",
    "2. Their seriousness about it\n",
    "\n",
    "So to capture this and reduce our possible values we can just cut it cleanly into the much more limited options of `religous_prefence` (8 possible values from my counts) and `religious_sentiment` (4 possible values) greatly reducing the possible values of this attribute from 45 possible values (excluding N/A) (Some entries don't have sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(lst, x, string1 = None):\n",
    "    if isinstance(x, str):\n",
    "        for l in lst:\n",
    "            if l.lower() in x.lower():\n",
    "                return l\n",
    "        if isinstance(string1, str):\n",
    "            return string1\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "religions = ['christianity', 'islam', 'judaism', 'buddhism', 'hinduism', 'agnosticism', 'atheism', 'other']\n",
    "profiles['religious_preference'] = profiles.religion.apply(lambda x: replacer(religions, x))\n",
    "\n",
    "\n",
    "sentiment = ['laughing about it', 'not too serious about it', 'somewhat serious about it', 'very serious about it']\n",
    "profiles['religious_sentiment'] = profiles.religion.apply(lambda x: replacer(sentiment, x, 'no opinion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>religious_preference</th>\n",
       "      <th>religious_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agnosticism</td>\n",
       "      <td>not too serious about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>christianity</td>\n",
       "      <td>not too serious about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atheism</td>\n",
       "      <td>laughing about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>christianity</td>\n",
       "      <td>very serious about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>other</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   religious_preference       religious_sentiment\n",
       "1           agnosticism  not too serious about it\n",
       "2                  <NA>                      <NA>\n",
       "3                  <NA>                      <NA>\n",
       "4                  <NA>                      <NA>\n",
       "6                  <NA>                      <NA>\n",
       "8          christianity  not too serious about it\n",
       "9               atheism         laughing about it\n",
       "10                 <NA>                      <NA>\n",
       "11         christianity     very serious about it\n",
       "12                other                no opinion"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working = create_working(profiles, split_map)\n",
    "working[[\"religious_preference\", \"religious_sentiment\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `sign`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign\n",
       "NaN                                              9912\n",
       "scorpio and it&rsquo;s fun to think about        1596\n",
       "gemini and it&rsquo;s fun to think about         1596\n",
       "leo and it&rsquo;s fun to think about            1522\n",
       "libra and it&rsquo;s fun to think about          1486\n",
       "taurus and it&rsquo;s fun to think about         1465\n",
       "sagittarius and it&rsquo;s fun to think about    1440\n",
       "aries and it&rsquo;s fun to think about          1431\n",
       "virgo and it&rsquo;s fun to think about          1422\n",
       "cancer and it&rsquo;s fun to think about         1421\n",
       "pisces and it&rsquo;s fun to think about         1420\n",
       "virgo but it doesn&rsquo;t matter                1361\n",
       "aquarius and it&rsquo;s fun to think about       1350\n",
       "cancer but it doesn&rsquo;t matter               1316\n",
       "taurus but it doesn&rsquo;t matter               1308\n",
       "leo but it doesn&rsquo;t matter                  1299\n",
       "gemini but it doesn&rsquo;t matter               1294\n",
       "aquarius but it doesn&rsquo;t matter             1273\n",
       "libra but it doesn&rsquo;t matter                1262\n",
       "capricorn and it&rsquo;s fun to think about      1254\n",
       "sagittarius but it doesn&rsquo;t matter          1236\n",
       "aries but it doesn&rsquo;t matter                1226\n",
       "capricorn but it doesn&rsquo;t matter            1193\n",
       "pisces but it doesn&rsquo;t matter               1182\n",
       "scorpio but it doesn&rsquo;t matter              1151\n",
       "leo                                              1049\n",
       "libra                                             997\n",
       "cancer                                            991\n",
       "virgo                                             938\n",
       "scorpio                                           915\n",
       "taurus                                            912\n",
       "aries                                             896\n",
       "gemini                                            892\n",
       "pisces                                            885\n",
       "aquarius                                          866\n",
       "sagittarius                                       838\n",
       "capricorn                                         749\n",
       "scorpio and it matters a lot                       71\n",
       "leo and it matters a lot                           62\n",
       "aquarius and it matters a lot                      60\n",
       "gemini and it matters a lot                        58\n",
       "cancer and it matters a lot                        57\n",
       "pisces and it matters a lot                        56\n",
       "sagittarius and it matters a lot                   44\n",
       "libra and it matters a lot                         44\n",
       "taurus and it matters a lot                        41\n",
       "aries and it matters a lot                         40\n",
       "capricorn and it matters a lot                     38\n",
       "virgo and it matters a lot                         36\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.sign.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign is very similar to religion and can be handled similarly. Only we seem to have a problem with character encoding. That can be easily fixed however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.sign = profiles.sign.apply(lambda x: x.replace('&rsquo;', \"\\'\") if isinstance(x, str) else x)\n",
    "star_signs = ['gemini', 'scorpio', 'leo', 'virgo', 'cancer', 'taurus', 'libra', 'aries', 'aquarius', 'pisces', 'capricorn', 'sagittarius']\n",
    "profiles['star_sign'] = profiles.sign.apply(lambda x: replacer(star_signs, x))\n",
    "\n",
    "sign_sentiment = ['it\\'s fun to think about', 'it doesn\\'t matter', 'it matters a lot']\n",
    "profiles['sign_sentiment'] = profiles.sign.apply(lambda x: replacer(sign_sentiment, x, 'no opinion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_sign</th>\n",
       "      <th>sign_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancer</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pisces</td>\n",
       "      <td>it doesn't matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pisces</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aquarius</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>virgo</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini</td>\n",
       "      <td>it doesn't matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cancer</td>\n",
       "      <td>it doesn't matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>taurus</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>leo</td>\n",
       "      <td>it doesn't matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>taurus</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_sign     sign_sentiment\n",
       "1     cancer         no opinion\n",
       "2     pisces  it doesn't matter\n",
       "3     pisces         no opinion\n",
       "4   aquarius         no opinion\n",
       "6      virgo         no opinion\n",
       "8     gemini  it doesn't matter\n",
       "9     cancer  it doesn't matter\n",
       "10    taurus         no opinion\n",
       "11       leo  it doesn't matter\n",
       "12    taurus         no opinion"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working = create_working(profiles, split_map)\n",
    "working[['star_sign', 'sign_sentiment']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `speaks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     english (fluently), spanish (poorly), french (...\n",
       "2                                  english, french, c++\n",
       "3                              english, german (poorly)\n",
       "4                                               english\n",
       "6                                               english\n",
       "8                                               english\n",
       "9                                    english (fluently)\n",
       "10                                              english\n",
       "11           english (fluently), sign language (poorly)\n",
       "12                                              english\n",
       "Name: speaks, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.speaks.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaks\n",
       "english                                                                        19616\n",
       "english (fluently)                                                              5967\n",
       "english (fluently), spanish (poorly)                                            1838\n",
       "english (fluently), spanish (okay)                                              1720\n",
       "english (fluently), spanish (fluently)                                          1181\n",
       "                                                                               ...  \n",
       "english (fluently), portuguese (fluently), spanish (fluently), french              1\n",
       "english (fluently), chinese (okay), dutch (poorly)                                 1\n",
       "english (fluently), italian (fluently), spanish (poorly), romanian (poorly)        1\n",
       "english (fluently), spanish (poorly), italian (poorly), khmer (poorly)             1\n",
       "english (fluently), ukrainian (fluently), russian (fluently)                       1\n",
       "Name: count, Length: 7078, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.speaks.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For speaks we are going to try something different, while we could list all the different languages, I feel capturing a person's english speaking ability would be a much more interesting attribute to have in our data. Let's just check how many of our subjects actually speak english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59896"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(profiles['speaks']))\n",
    "speakeasy = profiles['speaks'].str.contains(r'english', case = False, na = False).sum()\n",
    "int(speakeasy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially it appears that 50 of our subjects don't speak any english, but with a little tweaking of the above function you can find that these subjects just have No language data. Which for now isn't that important, its just something to be aware of.\n",
    "\n",
    "Now lets try and isolate the english part of each subjects language ability (if we have it of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english\n",
       "[english]                                                                                               26858\n",
       "[english (fluently)]                                                                                    25219\n",
       "[english (okay)]                                                                                          946\n",
       "[english (poorly)]                                                                                        531\n",
       "[english, english]                                                                                        104\n",
       "[english, english (fluently)]                                                                             103\n",
       "None                                                                                                       46\n",
       "[english (fluently), english]                                                                              29\n",
       "[english (fluently), english (fluently)]                                                                   27\n",
       "[english (fluently), english (poorly)]                                                                     20\n",
       "[english, english (okay)]                                                                                  13\n",
       "[english (fluently), english (okay), english (poorly)]                                                     11\n",
       "[english (fluently), english (okay)]                                                                        6\n",
       "[english, english (poorly)]                                                                                 5\n",
       "[english (okay), english (okay)]                                                                            5\n",
       "[english (fluently), english (fluently), english (fluently)]                                                4\n",
       "[english (poorly), english (okay), english (fluently)]                                                      2\n",
       "[english (fluently), english (poorly), english (okay)]                                                      2\n",
       "[english (fluently), english (fluently), english (fluently), english (fluently), english (fluently)]        2\n",
       "[english (fluently), english (fluently), english (fluently), english (fluently), english]                   2\n",
       "[english (fluently), english (fluently), english (okay)]                                                    1\n",
       "[english (fluently), english (okay), english (poorly), english (fluently), english (okay)]                  1\n",
       "[english, english (fluently), english (okay), english (poorly), english]                                    1\n",
       "[english (fluently), english (okay), english (poorly), english (fluently), english (poorly)]                1\n",
       "[english (fluently), english (fluently), english (okay), english (poorly)]                                  1\n",
       "[english (okay), english (fluently), english (poorly)]                                                      1\n",
       "[english (fluently), english (poorly), english (poorly)]                                                    1\n",
       "[english (okay), english (poorly)]                                                                          1\n",
       "[english, english (fluently), english (okay), english (poorly)]                                             1\n",
       "[english (poorly), english (okay), english (poorly)]                                                        1\n",
       "[english (okay), english (fluently)]                                                                        1\n",
       "[english (okay), english]                                                                                   1\n",
       "[english (okay), english (okay), english (okay)]                                                            1\n",
       "[english (poorly), english (okay), english (fluently), english, english]                                    1\n",
       "[english, english, english]                                                                                 1\n",
       "[english (poorly), english (poorly), english (poorly), english (poorly), english (poorly)]                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles[\"english\"] = profiles.speaks.apply(lambda x: x.lower().split(\",\") if isinstance(x, str) else x) #turn each string into a list (luckily our languages are already comma-seperated)\n",
    "profiles['english'] = profiles.english.apply(lambda x: [entry.lstrip() for entry in x if 'english' in entry.lower()] if isinstance(x, list) else None)\n",
    "\n",
    "working = create_working(profiles, split_map)\n",
    "working['english'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like some of our entries put multiple levels of english in their languages. Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english\n",
       "english              26982\n",
       "english(fluently)    25437\n",
       "english(okay)          954\n",
       "english(poorly)        532\n",
       "None                    46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a string to hold my personal ranking of english fluency to handle multiple english entries.\n",
    "english_scale = {'english(fluently)': 1, 'english': 2, 'english(okay)': 3, 'english(poorly)': 4}\n",
    "\n",
    "def fix_english(english_list:list, english_scale:dict):\n",
    "\n",
    "    current = english_list[0]\n",
    "    if len(english_list) > 1:\n",
    "        for i in range(1, len(english_list)):\n",
    "            if english_scale[current] > english_scale[english_list[i]]:\n",
    "                current = english_list[i]\n",
    "        return current\n",
    "    else:\n",
    "        return current\n",
    "\n",
    "profiles['english'] = profiles.english.apply(lambda x: [z.replace(\" \", \"\") for z in x] if isinstance(x, list) else None)\n",
    "profiles['english'] = profiles.english.apply(lambda x: fix_english(x, english_scale) if isinstance(x, list) else None)\n",
    "\n",
    "working = create_working(profiles, split_map)\n",
    "working['english'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's the english colomn sorted, looking a lot cleaner and a lot neater!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `offspring`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offspring\n",
       "doesn&rsquo;t have kids                                6851\n",
       "doesn&rsquo;t have kids, but might want them           3492\n",
       "doesn&rsquo;t have kids, but wants them                3202\n",
       "doesn&rsquo;t want kids                                2626\n",
       "has a kid                                              1697\n",
       "has kids                                               1683\n",
       "doesn&rsquo;t have kids, and doesn&rsquo;t want any     995\n",
       "has kids, but doesn&rsquo;t want more                   401\n",
       "has a kid, but doesn&rsquo;t want more                  242\n",
       "wants kids                                              207\n",
       "has a kid, and might want more                          206\n",
       "might want kids                                         168\n",
       "has kids, and might want more                            96\n",
       "has a kid, and wants more                                63\n",
       "has kids, and wants more                                 18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.offspring.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's keep things simple with this one and just refine it to those who have kids and those who do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kids_handler(x):\n",
    "    if isinstance(x, str):\n",
    "        result = x.split(\" kid\")[0]\n",
    "        if result == \"has a\":\n",
    "            return \"has\"\n",
    "        else:\n",
    "            return \"doesn't have\"\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offspring\n",
       "<NA>            35561\n",
       "doesn't have    21927\n",
       "has              2458\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.offspring = profiles.offspring.apply(lambda x: x.replace('&rsquo;', \"\\'\") if isinstance(x, str) else x)\n",
    "profiles['offspring'] = profiles.offspring.apply(lambda x: kids_handler(x))\n",
    "\n",
    "working = create_working(profiles, split_map)\n",
    "profiles.offspring.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `diet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet\n",
       "mostly anything        14860\n",
       "anything                5552\n",
       "strictly anything       4609\n",
       "mostly vegetarian       3093\n",
       "mostly other             894\n",
       "strictly vegetarian      790\n",
       "vegetarian               603\n",
       "strictly other           401\n",
       "mostly vegan             319\n",
       "other                    303\n",
       "strictly vegan           207\n",
       "vegan                    126\n",
       "mostly kosher             79\n",
       "mostly halal              45\n",
       "strictly kosher           16\n",
       "strictly halal            15\n",
       "halal                     10\n",
       "kosher                    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.diet.value_counts(dropna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "diets = ['vegetarian', 'vegan', 'anything', 'kosher', 'halal', 'other']\n",
    "profiles['diet'] = profiles['diet'].apply(lambda x: replacer(diets, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet\n",
       "NaN                    22019\n",
       "mostly anything        14860\n",
       "anything                5552\n",
       "strictly anything       4609\n",
       "mostly vegetarian       3093\n",
       "mostly other             894\n",
       "strictly vegetarian      790\n",
       "vegetarian               603\n",
       "strictly other           401\n",
       "mostly vegan             319\n",
       "other                    303\n",
       "strictly vegan           207\n",
       "vegan                    126\n",
       "mostly kosher             79\n",
       "mostly halal              45\n",
       "strictly kosher           16\n",
       "strictly halal            15\n",
       "halal                     10\n",
       "kosher                    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.diet.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplification Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We still have a few of our old attributes to remove, these being: `education`, `ethnicity`, `pets`, `religion`, `sign` and `speaks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                int64\n",
       "age                       int64\n",
       "body_type                object\n",
       "diet                     object\n",
       "drinks                   object\n",
       "drugs                    object\n",
       "height                  float64\n",
       "income                    int64\n",
       "job                      object\n",
       "last_online              object\n",
       "location                 object\n",
       "offspring                object\n",
       "orientation              object\n",
       "sex                      object\n",
       "smokes                   object\n",
       "status                   object\n",
       "unique_id                object\n",
       "which_set                object\n",
       "education_level          object\n",
       "education_status         object\n",
       "dogs                     object\n",
       "cats                     object\n",
       "religious_preference     object\n",
       "religious_sentiment      object\n",
       "star_sign                object\n",
       "sign_sentiment           object\n",
       "english                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.drop(columns = ['education', 'ethnicity', 'pets', 'religion', 'sign','speaks'], inplace = True)\n",
    "profiles.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Next up is check which values have nulls and then handling them if they do in a way that is essentially up to my own discretion, however I try to use multiple techniques to handle nulls. \n",
    "\n",
    "If we check our columns we can see that theres a few rows that are 100% good to go on that front but beyond this we have a select few rows mainly on extraneous personal data that our users probably didn't want to or coulnd't be bothered to fill in.\n",
    "\n",
    "My Null Handling Methodology:\n",
    "\n",
    "1. Find how many values are missing + what percentage of the attribute is missing\n",
    "2. Try and find out why they might be missing (MCAR, MAR, MNAR)\n",
    "3. Implement a solution to the nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "height                      3\n",
       "english                    50\n",
       "drinks                   2985\n",
       "body_type                5296\n",
       "smokes                   5512\n",
       "education_level          6628\n",
       "education_status         6628\n",
       "job                      8198\n",
       "sign_sentiment          11056\n",
       "star_sign               11056\n",
       "drugs                   14080\n",
       "dogs                    19921\n",
       "cats                    19921\n",
       "religious_sentiment     20226\n",
       "diet                    24395\n",
       "religious_preference    24984\n",
       "offspring               35561\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = profiles.isna().sum().sort_values()\n",
    "nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCAR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmissingno\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmsno\u001b[39;00m\n\u001b[0;32m      3\u001b[0m msno\u001b[38;5;241m.\u001b[39mheatmap(profiles, )\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.heatmap(profiles, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing High Null Rows\n",
    "\n",
    "I have decided that rows that have more than 40% of their attributes missing are to just be thrown out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape prior to removal:  (59946, 27)\n",
      "DataFrame shape post removal:  (58935, 27)\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame shape prior to removal: \", profiles.shape)\n",
    "profiles['null_count'] = profiles.isna().sum(axis = 1)\n",
    "profiles = profiles[profiles['null_count'] < (0.4 * profiles.shape[1])]\n",
    "profiles.drop(columns = ['null_count'], inplace = True)\n",
    "print(\"DataFrame shape post removal: \", profiles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english                    39\n",
       "drinks                   2171\n",
       "smokes                   4654\n",
       "body_type                4943\n",
       "education_level          5683\n",
       "education_status         5683\n",
       "job                      7267\n",
       "sign_sentiment          10085\n",
       "star_sign               10085\n",
       "drugs                   13740\n",
       "dogs                    18920\n",
       "cats                    18920\n",
       "religious_sentiment     19243\n",
       "diet                    23465\n",
       "religious_preference    23997\n",
       "offspring               34571\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = profiles.isna().sum().sort_values()\n",
    "nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `english` Nulls\n",
    "\n",
    "`english` null count is low enough to be handled by **listwise deletion**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles[~profiles['english'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `drinks` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['drinks'] = profiles['drinks'].fillna('rather not say')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `body_type` nulls\n",
    "\n",
    "All nulls in the body type column are replaced with the average. This is done as the majority of people would have the average body type anyway.\n",
    "\n",
    "Note: Think about this assumption more critically.\n",
    "\n",
    "Note: This is an assumption, put it in the assumptions section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['body_type'] = profiles['body_type'].fillna('average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `smokes` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['smokes'] = profiles['smokes'].fillna('rather not say')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `education_status` and `education level` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education_level\n",
      "college/university    28281\n",
      "masters                9846\n",
      "<NA>                   5106\n",
      "two-year college       2680\n",
      "ph.d                   2149\n",
      "high school            1534\n",
      "space camp             1513\n",
      "law school             1281\n",
      "med school              623\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "education_status\n",
       "graduated      36615\n",
       "working on      9405\n",
       "<NA>            5106\n",
       "dropped out     1887\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working = create_working(profiles, split_map)\n",
    "\n",
    "print(working.education_level.value_counts(dropna = False))\n",
    "working.education_status.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `job` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['job'] = profiles['job'].fillna('unspecified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `sign_sentiment` and `star_sign` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.drop(columns = ['sign_sentiment', 'star_sign'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `drugs` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['drugs'] = profiles['drugs'].fillna('unspecified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `dogs` and `cats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.drop(columns = ['dogs', 'cats'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `religous_sentiment` and `religous_preference` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['religious_sentiment'] = profiles['religious_sentiment'].fillna('not specified')\n",
    "profiles['religious_preference'] = profiles['religious_preference'].fillna('not specified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `diet` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['diet'] = profiles['diet'].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.drop(columns = ['offspring'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers\n",
    "\n",
    "### Handling `age` outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.dtypes[profiles.dtypes == pd.Int64Dtype()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age is numerical so describe should give us a good idea of the distribution of the values (we already know the age column contains no nulls)\n",
    "profiles['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = profiles, x = 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ages above 100 are removed\n",
    "profiles = profiles[profiles[\"age\"] <= 100]\n",
    "profiles['age'].describe() #resulting distribution looks a lot more realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = profiles, x = 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `height` Outliers\n",
    "\n",
    "Next is handling height, and taking a look immediately at the results of the `.describe()` method we can see  a big problem. our min height is someone who claims to be one inch tall. Moving on to the box plot we can see that a few people are also claiming to have a height smaller than the smallest person in the world Chandra Bahadur Dangi who is 21.5 inches tall. So let's immediately remove these jokers from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = profiles, x = 'height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles[profiles[\"height\"] >= 40]\n",
    "profiles['height'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `income` outliers\n",
    "\n",
    "One Thing we can notice about our income attributre is that most of our entries are in the category -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.income.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.loc[profiles['income'] == -1, 'income'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Inconsistent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.location.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body Type Variation\n",
    "\n",
    "As we can see most people on the site consider themselves to be either average or fit/athletic, you would expect this as most people with societaly dictated \"negative\" body type would not be confident enough to be on a dating website or less likely to report this feature of themselves accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['body_type'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My order is based on my own determination of a logical order for the available values for body_type based on my own perception of less fit to most fit\n",
    "my_order = ['rather not say', 'overweight', 'used up', 'curvy', 'full figured', 'a little extra', 'thin', 'skinny', 'average', 'fit', 'athletic', 'jacked']\n",
    "ax = sns.countplot(data = profiles, x = 'body_type', hue = 'body_type', order = my_order, hue_order = my_order)\n",
    "\n",
    "#Just wanted to put in the count values on top of each bar so as to better interpret the data for ease of interpretability. This is all done in 1000s points for fit.\n",
    "for axi in ax.patches:\n",
    "    height = axi.get_height()\n",
    "    ax.text(axi.get_x()+axi.get_width()/2.,\n",
    "            height + 3,\n",
    "            f'{round(axi.get_height() / 1000, 1)}K',\n",
    "            ha=\"center\")\n",
    "\n",
    "#rotate labels for no overlap     \n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Diet Nulls\n",
    "\n",
    "So when we look at the diet data we see that a wopping 68% of the data is NA so our users didnt specify diet data.\n",
    "\n",
    "It would be best to keep set nulls as a new category (\"not specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### I FIND THIS INSUFFICIENT ######\n",
    "# Probably want to compare the distribution of missing values according to age (maybe other variables) and present values to see if this missingness is actually random \n",
    "profiles['diet'] = profiles['diet'].fillna('anything')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diet Variation\n",
    "\n",
    "Most people on the site expectedly have little to no dietary restriction or preference. Neglibile amounts of people on the dating site conform to religious diets (Maybe our site isn't that appealling to a religious audience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "profiles['diet'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6), dpi=80)\n",
    "\n",
    "ax = sns.countplot(data = profiles, x = 'diet', hue = 'diet')\n",
    "\n",
    "#Just wanted to put in the count values on top of each bar so as to better interpret the data for ease of interpretability. This is all done in 1000s points for fit.\n",
    "for axi in ax.patches:\n",
    "    height = axi.get_height()\n",
    "    ax.text(axi.get_x()+axi.get_width()/2.,\n",
    "            height + 3,\n",
    "            f'{round(axi.get_height() / 1000, 1)}K',\n",
    "            ha=\"center\")\n",
    "\n",
    "#rotate labels for no overlap     \n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45, ha = \"right\", x = -0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Handling Drinks and Drugs Nulls\n",
    "\n",
    "So we have a few missing drugs and less amount of missing drinks. This would be a good time to test if people are just leaving the field empty for personal reasons or is it just random?\n",
    "\n",
    "From looking at the p values of the prevalence of drinks and drugs with other factors such as age, sex, income, edication and religion. \n",
    "\n",
    "1. We can see that people with certain religious beliefs are likely to skip drug related questions and to a lesser extent drink related questions.\n",
    "2. Socioeconomic and demograpgic factors influence response rates for these attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_square_missing(profiles, missing_col, categorical_col): # < 0.05 returned suggests MAR\n",
    "    profiles_copy = profiles.copy()\n",
    "    profiles_copy['missing'] = profiles_copy[missing_col].isna().astype(int)\n",
    "\n",
    "    contingency_table = pd.crosstab(profiles_copy['missing'], profiles_copy[categorical_col])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    return p\n",
    "\n",
    "for col in ['age', 'sex', 'education', 'income', 'religion']:\n",
    "    p_value = chi_square_missing(profiles, 'drugs', col)\n",
    "    print(f\"Missingness in drugs vs. {col}: p-value = {p_value}\")\n",
    "\n",
    "    p_value = chi_square_missing(profiles, 'drinks', col)\n",
    "    print(f\"Missingness in drinks vs. {col}: p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drink and Drugs Variation\n",
    "\n",
    "While the drinks attribute has a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profiles['drugs'].value_counts(dropna = False), \"\\n\")\n",
    "print(profiles['drinks'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data = profiles[profiles['drugs'] != 'never'], x = 'drinks', hue = 'drugs', )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Variation\n",
    "\n",
    "This attribute is need of serious cleaning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_desc = profiles['education'].describe()\n",
    "print(edu_desc)\n",
    "profiles['education'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envoid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
