{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoping\n",
    "\n",
    "### Project Goals\n",
    "\n",
    "This project is designed to utilize the skills I have learned and apply machine learning techniques to a data set. I went into this project blind and thus this project is meant to outline my method to understand and refine a dataset from scratch and derive insights from it. The initial guidance I recieved was to decide a research question at this point but without understanding the contents of a dataset, its limits and quirks, that would in my humble opinion be impossible to do.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "My Method is inspired by the one provided in: {insert book title here} (which is available neatly in appendix B pg. 497). \n",
    "\n",
    "However, against the apparent rigid and formulaic nature of the method provided therin I prefer to keep my processes iterative (recursive in a way) and dynamic. The format of this document may lead to you believe that I have gone about this project in clear steps and stages but this is mostly a function of the need for presentability and concistency. The process here is iterative and dynamic.\n",
    "    \n",
    "(Especially between the cleaning and exploratitory parts there is a lot of back and forth in understanding and refining the dataset to a state of usability I deem acceptable.)\n",
    "\n",
    "1. Preliminary Analysis- Quick look at the dataset, preparation for test integrity and initial assessment of usefullness for the task ahead. NOTE -> \"This next part for exploratory analyisis?\" the its noisiness, distribution and possible usefulness for the task ahead. \"This should be put in at least cleaning data as noise reduction would be a cleaning operation\" END NOTE\n",
    "2. Cleaning Data - serves primarily as a cleaning of the dataset but also as an initial analysis of each of the attributes. (This is exhaustive but also good practice in refining a dataset)\n",
    "3. Exploratory Analysis - Explore the datasets relationships and patterns (Note: this is done after the clean so as to not have the exploration biased by missing values, incorrect inputs e.tc )\n",
    "4. Framing - Decide and Assess an objective, think about what a solution would look like, how I would measure its performance and list assumptions.\n",
    "5. Experimentation and refienment - testing models, validating them and evaluating them.\n",
    "6. Presentation and Interpretation - show the results and interpet them in the context of the research question\n",
    "\n",
    "The primary research question that I have detemerined to be answered is that of whether\n",
    "\n",
    "### Assumptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python Modules\n",
    "First things first is to import the python modules I will be using for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "The first step I take is to load the provided data into a pandas DataFrame object so that it can be efficiently explored and manipulated in python.\n",
    "\n",
    "This involves the file `profiles.csv` being loaded into the `profiles` DataFrame. It is subsequently displayed for examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\r\\n&lt;br /&gt;\\r\\ni would love to t...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\r\\nranting about a ...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\r\\...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\r\\nhttp://b...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education  \\\n",
       "0      working on college/university   \n",
       "1              working on space camp   \n",
       "2     graduated from masters program   \n",
       "3      working on college/university   \n",
       "4  graduated from college/university   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\r\\n<br />\\r\\ni would love to t...   \n",
       "1  i am a chef: this is what that means.<br />\\r\\...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\r\\nranting about a ...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\r\\nhttp://b...   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  the way i look. i am a six foot half asian, ha...  ...   \n",
       "1                                                NaN  ...   \n",
       "2  my large jaw and large glasses are the physica...  ...   \n",
       "3                  socially awkward but i do my best  ...   \n",
       "4            i smile a lot and my inquisitive nature  ...   \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "2        san francisco, california   \n",
       "3             berkeley, california   \n",
       "4        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "3                           english, german (poorly)     single  \n",
       "4                                            english     single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('profiles.csv', encoding = 'utf-8')\n",
    "df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight away I can tell there is no point in looking at the value counts of the `essay{number}` columns as they are more likely infinitely variable, will not have any repeating entries and this project doesn't involve NLP. Let's drop them immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = [f'essay{i}' for i in range(0, 10, 1)]\n",
    "df.drop(essays, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the Data Characteristics\n",
    "\n",
    "First it is advisable to look at the data types and columns presented to us in the data and determine how much data we are dealing with exactly.\n",
    "\n",
    "Doing a few simple calls to variables of the dataframe reveals that our dating profiles data consists of 59,946 rows (or users) and 31 attributes/columns.\n",
    "\n",
    "Each column's name is sort of self descriptive of what sort of information is expected therein so there is no need to elaborate them here, any nuance within them will be explained in further parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   body_type    54650 non-null  object \n",
      " 2   diet         35551 non-null  object \n",
      " 3   drinks       56961 non-null  object \n",
      " 4   drugs        45866 non-null  object \n",
      " 5   education    53318 non-null  object \n",
      " 6   ethnicity    54266 non-null  object \n",
      " 7   height       59943 non-null  float64\n",
      " 8   income       59946 non-null  int64  \n",
      " 9   job          51748 non-null  object \n",
      " 10  last_online  59946 non-null  object \n",
      " 11  location     59946 non-null  object \n",
      " 12  offspring    24385 non-null  object \n",
      " 13  orientation  59946 non-null  object \n",
      " 14  pets         40025 non-null  object \n",
      " 15  religion     39720 non-null  object \n",
      " 16  sex          59946 non-null  object \n",
      " 17  sign         48890 non-null  object \n",
      " 18  smokes       54434 non-null  object \n",
      " 19  speaks       59896 non-null  object \n",
      " 20  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 9.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include = 'object').columns:\n",
    "    df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Asside A Sample Test Set\n",
    "\n",
    "This ensures we keep data snooping bias out of our project! The dataset is quite large so I am assuming there is no need for stratefied sampling. The following code ensures that we can reuse our split despite modification or removal of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Uncomment the following code to create new csv with identifiers###\n",
    "#from reproducable_split import add_identifiers\n",
    "#add_identifiers(df, create_new = True, new_name = \"profiles_identifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment the following code to create a new split map ###\n",
    "#from reproducable_split import create_splitmap\n",
    "#profiles = pd.read_csv(\"profiles_identifiers.csv\")\n",
    "#create_splitmap(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>...</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>which_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>...</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "      <td>72576212e92f49d0b12653edfe9737df</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "      <td>38aae2317e0341a9bf2908cb6d170997</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>...</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "      <td>3a7595b8e3594690b51855ebdb8aa6a0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "      <td>44485df4cfa04740ab3e173226c652bf</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>fit</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>white, other</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>virgo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "      <td>7e39b9ae441d41ad859bcbbce8c0b847</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age body_type               diet    drinks      drugs  \\\n",
       "1           1   35   average       mostly other     often  sometimes   \n",
       "2           2   38      thin           anything  socially        NaN   \n",
       "3           3   23      thin         vegetarian  socially        NaN   \n",
       "4           4   29  athletic                NaN  socially      never   \n",
       "6           6   32       fit  strictly anything  socially      never   \n",
       "\n",
       "                           education            ethnicity  height  income  \\\n",
       "1              working on space camp                white    70.0   80000   \n",
       "2     graduated from masters program                  NaN    68.0      -1   \n",
       "3      working on college/university                white    71.0   20000   \n",
       "4  graduated from college/university  asian, black, other    66.0      -1   \n",
       "6  graduated from college/university         white, other    65.0      -1   \n",
       "\n",
       "   ... orientation                       pets  \\\n",
       "1  ...    straight  likes dogs and likes cats   \n",
       "2  ...    straight                   has cats   \n",
       "3  ...    straight                 likes cats   \n",
       "4  ...    straight  likes dogs and likes cats   \n",
       "6  ...    straight  likes dogs and likes cats   \n",
       "\n",
       "                                   religion sex  \\\n",
       "1  agnosticism but not too serious about it   m   \n",
       "2                                       NaN   m   \n",
       "3                                       NaN   m   \n",
       "4                                       NaN   m   \n",
       "6                                       NaN   f   \n",
       "\n",
       "                                 sign smokes  \\\n",
       "1                              cancer     no   \n",
       "2  pisces but it doesn&rsquo;t matter     no   \n",
       "3                              pisces     no   \n",
       "4                            aquarius     no   \n",
       "6                               virgo    NaN   \n",
       "\n",
       "                                              speaks     status  \\\n",
       "1  english (fluently), spanish (poorly), french (...     single   \n",
       "2                               english, french, c++  available   \n",
       "3                           english, german (poorly)     single   \n",
       "4                                            english     single   \n",
       "6                                            english     single   \n",
       "\n",
       "                          unique_id which_set  \n",
       "1  72576212e92f49d0b12653edfe9737df     train  \n",
       "2  38aae2317e0341a9bf2908cb6d170997     train  \n",
       "3  3a7595b8e3594690b51855ebdb8aa6a0     train  \n",
       "4  44485df4cfa04740ab3e173226c652bf     train  \n",
       "6  7e39b9ae441d41ad859bcbbce8c0b847     train  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we bring in the profiles with identifiers I have created earlier\n",
    "profiles = pd.read_csv(\"profiles_identifiers.csv\")\n",
    "\n",
    "#As well as the split map\n",
    "split_map = pd.read_csv(\"split_mapping.csv\")\n",
    "\n",
    "new_df = profiles.merge(split_map, on = \"unique_id\", how = \"inner\")\n",
    "train_df = new_df[new_df[\"which_set\"] == \"train\"]\n",
    "test_df = new_df[new_df[\"which_set\"] == \"test\"]\n",
    "\n",
    "working = train_df.copy()\n",
    "working.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "First up is to clean the data and make sure it is suitable for use. My cleaning process for a single dataset consists of five steps:\n",
    "\n",
    "\n",
    "1. Handling duplicate rows\n",
    "2. Simplifying and standardizng attributes \n",
    "3. Handling missing values\n",
    "4. Handling outliers + noise\n",
    "5. Handling inconsitent attributes \n",
    "\n",
    "## Handling Duplicates\n",
    "\n",
    "First let's check if there are any duplicate entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are all clear on duplicate entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying attributes\n",
    "\n",
    "This section's general aim is to simplify primarily categorical attributes that have way too many different catagories and potentially give NA entries actual values.\n",
    "\n",
    "From a brief look at the number of unique values and a little reference back up to our dtypes (plus a little behind the scenes checks on value counts) we can see that a few columns are up for a little simplification, these being:\n",
    "\n",
    "1. education\n",
    "2. ethnicity\n",
    "3. speaks\n",
    "4. pets\n",
    "5. religion\n",
    "6. sign\n",
    "7. speaks\n",
    "8. diet\n",
    "9. offspring\n",
    "\n",
    "Additionally we want to sort out the corrupted strings in:\n",
    "1. offspring\n",
    "2. sign\n",
    "\n",
    "#NOTE INCOME IS FUNNY AS IT MIGHT AS WELL BE CATEGORICAL AS IT IS A SET OF NUMERICAL BRACKETS (ie. 20000, 100000, 80000) that people are put under."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "graduated from college/university    21574\n",
       "graduated from masters program        8095\n",
       "NaN                                   5953\n",
       "working on college/university         5147\n",
       "working on masters program            1529\n",
       "graduated from two-year college       1374\n",
       "graduated from high school            1276\n",
       "graduated from ph.d program           1138\n",
       "graduated from law school             1003\n",
       "working on two-year college            944\n",
       "dropped out of college/university      888\n",
       "working on ph.d program                882\n",
       "college/university                     725\n",
       "graduated from space camp              599\n",
       "dropped out of space camp              470\n",
       "graduated from med school              412\n",
       "working on space camp                  396\n",
       "working on law school                  250\n",
       "two-year college                       197\n",
       "working on med school                  190\n",
       "dropped out of two-year college        167\n",
       "dropped out of masters program         125\n",
       "masters program                        121\n",
       "dropped out of ph.d program            116\n",
       "dropped out of high school              95\n",
       "high school                             83\n",
       "working on high school                  80\n",
       "space camp                              48\n",
       "ph.d program                            21\n",
       "law school                              16\n",
       "dropped out of law school               15\n",
       "dropped out of med school               11\n",
       "med school                              11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.education.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(lst, x, string1 = None):\n",
    "    if isinstance(x, str):\n",
    "        for l in lst:\n",
    "            if l.lower() in x.lower():\n",
    "                return l\n",
    "        if isinstance(string1, str):\n",
    "            return string1\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education_level\n",
      "college/university    31467\n",
      "masters               10920\n",
      "<NA>                   6628\n",
      "two-year college       3018\n",
      "ph.d                   2408\n",
      "high school            1713\n",
      "space camp             1683\n",
      "law school             1428\n",
      "med school              681\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "education_status\n",
       "graduated      40745\n",
       "working on     10465\n",
       "<NA>            6628\n",
       "dropped out     2108\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new column for education level\n",
    "edu = ['space camp', 'high school', 'two-year college', 'college/university', 'law school', 'med school', 'masters', 'ph.d']\n",
    "profiles['education_level'] = profiles['education'].apply(lambda x: replacer(edu, x))\n",
    "\n",
    "#create new column for education status \n",
    "edu = ['dropped out', 'working on', 'graduated']\n",
    "profiles['education_status'] = profiles['education'].apply(lambda x: replacer(edu, x, 'graduated'))\n",
    "\n",
    "print(profiles.education_level.value_counts(dropna = False))\n",
    "profiles.education_status.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           asian, white\n",
       "1                  white\n",
       "2                    NaN\n",
       "3                  white\n",
       "4    asian, black, other\n",
       "5                  white\n",
       "6           white, other\n",
       "7                  white\n",
       "8                  white\n",
       "9                  white\n",
       "Name: ethnicity, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.ethnicity.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity\n",
       "white                                                                               32831\n",
       "asian                                                                                6134\n",
       "NaN                                                                                  5680\n",
       "hispanic / latin                                                                     2823\n",
       "black                                                                                2008\n",
       "                                                                                    ...  \n",
       "asian, black, pacific islander, hispanic / latin, white                                 1\n",
       "asian, native american, indian, pacific islander, hispanic / latin, white, other        1\n",
       "asian, middle eastern, black, pacific islander, hispanic / latin                        1\n",
       "asian, black, pacific islander, white, other                                            1\n",
       "asian, black, indian                                                                    1\n",
       "Name: count, Length: 218, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles['ethnicity'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of first things we can notice about our ethnicity values is that there are a lot of people who are an ethnicity onto themselves, which might be interesting for anthropologists but unfortunately for us is not very good for ML models as they aren't very generalizable.\n",
    "\n",
    "Let's make things a bit simpler and of course this involves an assumption:\n",
    "\n",
    "1. If a person has multiple ethnicities (more than 3) they can be assumed to be part of a group (mixed) and that this group can be generalized to be the same and the patterns in the data are still maintained. (FLAWED?)\n",
    "\n",
    "The rest will be simplified by splitting people into their primary and secondary ethnicity (the majority of the dataset adheres to this cleanly) while people with multiple ethnicities will be put down as mixed for both ethnicity 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a little helper function made to cut down any multiple ethnicity entires into something more palatable.\n",
    "#Comments explain what it does for this particualr attribute.\n",
    "def long_handler(x, string1):\n",
    "    if isinstance(x, str):\n",
    "        x = x.split(\",\")\n",
    "\n",
    "        if len(x) < 3:\n",
    "            if len(x) == 1:\n",
    "                return(x.pop()) # if someone is just 1 ethnicity than return that one ethnicity\n",
    "            else:\n",
    "                return x # if someone is two ethnicities than just send those back too\n",
    "        else:\n",
    "            return string1 #if the number of ethnicities a person is, is greater than 3 then return them as mixed\n",
    "    \n",
    "    else:\n",
    "        return pd.NA #if the entry is N/A or somehow not a string then return N/A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ethnicity_1</th>\n",
       "      <th>ethnicity_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixed</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>white</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ethnicity_1 ethnicity_2\n",
       "0       asian       white\n",
       "1       white       white\n",
       "2        <NA>        <NA>\n",
       "3       white       white\n",
       "4       mixed       mixed\n",
       "5       white       white\n",
       "6       white       other\n",
       "7       white       white\n",
       "8       white       white\n",
       "9       white       white"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.ethnicity = profiles.ethnicity.apply(lambda x: long_handler(x, 'mixed'))\n",
    "profiles[\"ethnicity_1\"] = profiles.ethnicity.apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "profiles[\"ethnicity_2\"] = profiles.ethnicity.apply(lambda x: x[1] if isinstance(x, list) else x)\n",
    "\n",
    "profiles[[\"ethnicity_1\", \"ethnicity_2\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying Pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pets\n",
       "NaN                                19921\n",
       "likes dogs and likes cats          14814\n",
       "likes dogs                          7224\n",
       "likes dogs and has cats             4313\n",
       "has dogs                            4134\n",
       "has dogs and likes cats             2333\n",
       "likes dogs and dislikes cats        2029\n",
       "has dogs and has cats               1474\n",
       "has cats                            1406\n",
       "likes cats                          1063\n",
       "has dogs and dislikes cats           552\n",
       "dislikes dogs and likes cats         240\n",
       "dislikes dogs and dislikes cats      196\n",
       "dislikes cats                        122\n",
       "dislikes dogs and has cats            81\n",
       "dislikes dogs                         44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.pets.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pets` column has a lot of different categories but can be easily simplified into two columns where cat and dog dispositions are represented seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another little helper function made to seprate our pet lovers opinions on cats and dogs clearly.\n",
    "def pet_sentiment(x, pet: str):\n",
    "\n",
    "    if isinstance(x, str):\n",
    "        if \" and \" in x:\n",
    "            result = x.split(\" and \")\n",
    "            if pet == 'dog':\n",
    "                result1 = result[0].removesuffix(\" dogs\")\n",
    "                return result1\n",
    "            elif pet == 'cat':\n",
    "                result2 = result[1].removesuffix(\" cats\")\n",
    "                return result2\n",
    "    \n",
    "        elif  pet == 'dog':\n",
    "            if \"dogs\" in x:\n",
    "                result1 = x.removesuffix(\" dogs\")\n",
    "                return result1\n",
    "            else:\n",
    "                return 'no opinion'\n",
    "        elif pet == 'cat':\n",
    "            if \"cats\" in x:\n",
    "                result2 = x.removesuffix(\" cats\")\n",
    "                return result2\n",
    "            else:\n",
    "                return 'no opinion'\n",
    "    else:   \n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cats</th>\n",
       "      <th>dogs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>likes</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>likes</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>likes</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>likes</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>has</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>has</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>likes</td>\n",
       "      <td>likes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cats        dogs\n",
       "0   likes       likes\n",
       "1   likes       likes\n",
       "2     has  no opinion\n",
       "3   likes  no opinion\n",
       "4   likes       likes\n",
       "5   likes  no opinion\n",
       "6   likes       likes\n",
       "7   likes       likes\n",
       "8   likes       likes\n",
       "9   likes       likes\n",
       "10   <NA>        <NA>\n",
       "11  likes  no opinion\n",
       "12   <NA>        <NA>\n",
       "13  likes         has\n",
       "14    has       likes\n",
       "15    has       likes\n",
       "16  likes       likes\n",
       "17   <NA>        <NA>\n",
       "18  likes       likes\n",
       "19  likes       likes"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles['dogs'] = profiles.pets.apply(lambda x: pet_sentiment(x, 'dog'))\n",
    "profiles['cats'] = profiles.pets.apply(lambda x: pet_sentiment(x, 'cat'))\n",
    "\n",
    "profiles[['cats', 'dogs']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `religion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion\n",
       "NaN                                           20226\n",
       "agnosticism                                    2724\n",
       "other                                          2691\n",
       "agnosticism but not too serious about it       2636\n",
       "agnosticism and laughing about it              2496\n",
       "catholicism but not too serious about it       2318\n",
       "atheism                                        2175\n",
       "other and laughing about it                    2119\n",
       "atheism and laughing about it                  2074\n",
       "christianity                                   1957\n",
       "christianity but not too serious about it      1952\n",
       "other but not too serious about it             1554\n",
       "judaism but not too serious about it           1517\n",
       "atheism but not too serious about it           1318\n",
       "catholicism                                    1064\n",
       "christianity and somewhat serious about it      927\n",
       "atheism and somewhat serious about it           848\n",
       "other and somewhat serious about it             846\n",
       "catholicism and laughing about it               726\n",
       "judaism and laughing about it                   681\n",
       "buddhism but not too serious about it           650\n",
       "agnosticism and somewhat serious about it       642\n",
       "judaism                                         612\n",
       "christianity and very serious about it          578\n",
       "atheism and very serious about it               570\n",
       "catholicism and somewhat serious about it       548\n",
       "other and very serious about it                 533\n",
       "buddhism and laughing about it                  466\n",
       "buddhism                                        403\n",
       "christianity and laughing about it              373\n",
       "buddhism and somewhat serious about it          359\n",
       "agnosticism and very serious about it           314\n",
       "judaism and somewhat serious about it           266\n",
       "hinduism but not too serious about it           227\n",
       "hinduism                                        107\n",
       "catholicism and very serious about it           102\n",
       "buddhism and very serious about it               70\n",
       "hinduism and somewhat serious about it           58\n",
       "islam                                            48\n",
       "hinduism and laughing about it                   44\n",
       "islam but not too serious about it               40\n",
       "islam and somewhat serious about it              22\n",
       "judaism and very serious about it                22\n",
       "islam and laughing about it                      16\n",
       "hinduism and very serious about it               14\n",
       "islam and very serious about it                  13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.religion.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another attribute with a lot of N/A but looking at the actual data here we can clearly see that this attribute containts two specific parts of a persons religion. These being\n",
    "1. Their actual religion\n",
    "2. Their seriousness about it\n",
    "\n",
    "So to capture this and reduce our possible values we can just cut it cleanly into the much more limited options of `religous_prefence` (8 possible values from my counts) and `religious_sentiment` (4 possible values) greatly reducing the possible values of this attribute from 45 possible values (excluding N/A) (Some entries don't have sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(lst, x, string1 = None):\n",
    "    if isinstance(x, str):\n",
    "        for l in lst:\n",
    "            if l.lower() in x.lower():\n",
    "                return l\n",
    "        if isinstance(string1, str):\n",
    "            return string1\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "religions = ['christianity', 'islam', 'judaism', 'buddhism', 'hinduism', 'agnosticism', 'atheism', 'other']\n",
    "profiles['religious_preference'] = profiles.religion.apply(lambda x: replacer(religions, x))\n",
    "\n",
    "\n",
    "sentiment = ['laughing about it', 'not too serious about it', 'somewhat serious about it', 'very serious about it']\n",
    "profiles['religious_sentiment'] = profiles.religion.apply(lambda x: replacer(sentiment, x, 'no opinion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>religious_preference</th>\n",
       "      <th>religious_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agnosticism</td>\n",
       "      <td>very serious about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agnosticism</td>\n",
       "      <td>not too serious about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>atheism</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>christianity</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>christianity</td>\n",
       "      <td>not too serious about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atheism</td>\n",
       "      <td>laughing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  religious_preference       religious_sentiment\n",
       "0          agnosticism     very serious about it\n",
       "1          agnosticism  not too serious about it\n",
       "2                 <NA>                      <NA>\n",
       "3                 <NA>                      <NA>\n",
       "4                 <NA>                      <NA>\n",
       "5              atheism                no opinion\n",
       "6                 <NA>                      <NA>\n",
       "7         christianity                no opinion\n",
       "8         christianity  not too serious about it\n",
       "9              atheism         laughing about it"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles[[\"religious_preference\", \"religious_sentiment\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `sign`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign\n",
       "NaN                                              11056\n",
       "gemini and it&rsquo;s fun to think about          1782\n",
       "scorpio and it&rsquo;s fun to think about         1772\n",
       "leo and it&rsquo;s fun to think about             1692\n",
       "libra and it&rsquo;s fun to think about           1649\n",
       "taurus and it&rsquo;s fun to think about          1640\n",
       "cancer and it&rsquo;s fun to think about          1597\n",
       "pisces and it&rsquo;s fun to think about          1592\n",
       "sagittarius and it&rsquo;s fun to think about     1583\n",
       "virgo and it&rsquo;s fun to think about           1574\n",
       "aries and it&rsquo;s fun to think about           1573\n",
       "aquarius and it&rsquo;s fun to think about        1503\n",
       "virgo but it doesn&rsquo;t matter                 1497\n",
       "leo but it doesn&rsquo;t matter                   1457\n",
       "cancer but it doesn&rsquo;t matter                1454\n",
       "gemini but it doesn&rsquo;t matter                1453\n",
       "taurus but it doesn&rsquo;t matter                1450\n",
       "aquarius but it doesn&rsquo;t matter              1408\n",
       "libra but it doesn&rsquo;t matter                 1408\n",
       "capricorn and it&rsquo;s fun to think about       1376\n",
       "sagittarius but it doesn&rsquo;t matter           1375\n",
       "aries but it doesn&rsquo;t matter                 1373\n",
       "capricorn but it doesn&rsquo;t matter             1319\n",
       "pisces but it doesn&rsquo;t matter                1300\n",
       "scorpio but it doesn&rsquo;t matter               1264\n",
       "leo                                               1159\n",
       "libra                                             1098\n",
       "cancer                                            1092\n",
       "virgo                                             1029\n",
       "scorpio                                           1020\n",
       "gemini                                            1013\n",
       "taurus                                            1001\n",
       "aries                                              996\n",
       "pisces                                             992\n",
       "aquarius                                           954\n",
       "sagittarius                                        937\n",
       "capricorn                                          833\n",
       "scorpio and it matters a lot                        78\n",
       "leo and it matters a lot                            66\n",
       "cancer and it matters a lot                         63\n",
       "aquarius and it matters a lot                       63\n",
       "gemini and it matters a lot                         62\n",
       "pisces and it matters a lot                         62\n",
       "libra and it matters a lot                          52\n",
       "taurus and it matters a lot                         49\n",
       "sagittarius and it matters a lot                    47\n",
       "aries and it matters a lot                          47\n",
       "capricorn and it matters a lot                      45\n",
       "virgo and it matters a lot                          41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.sign.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign is very similar to religion and can be handled similarly. Only we seem to have a problem with character encoding. That can be easily fixed however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.sign = profiles.sign.apply(lambda x: x.replace('&rsquo;', \"\\'\") if isinstance(x, str) else x)\n",
    "star_signs = ['gemini', 'scorpio', 'leo', 'virgo', 'cancer', 'taurus', 'libra', 'aries', 'aquarius', 'pisces', 'capricorn', 'sagittarius']\n",
    "profiles['star_sign'] = profiles.sign.apply(lambda x: replacer(star_signs, x))\n",
    "\n",
    "sign_sentiment = ['it\\'s fun to think about', 'it doesn\\'t matter', 'it matters a lot']\n",
    "profiles['sign_sentiment'] = profiles.sign.apply(lambda x: replacer(sign_sentiment, x, 'no opinion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_sign</th>\n",
       "      <th>sign_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemini</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancer</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pisces</td>\n",
       "      <td>it doesn't matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pisces</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aquarius</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>taurus</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>virgo</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sagittarius</td>\n",
       "      <td>no opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini</td>\n",
       "      <td>it doesn't matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cancer</td>\n",
       "      <td>it doesn't matter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     star_sign     sign_sentiment\n",
       "0       gemini         no opinion\n",
       "1       cancer         no opinion\n",
       "2       pisces  it doesn't matter\n",
       "3       pisces         no opinion\n",
       "4     aquarius         no opinion\n",
       "5       taurus         no opinion\n",
       "6        virgo         no opinion\n",
       "7  sagittarius         no opinion\n",
       "8       gemini  it doesn't matter\n",
       "9       cancer  it doesn't matter"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles[['star_sign', 'sign_sentiment']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `speaks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              english\n",
       "1    english (fluently), spanish (poorly), french (...\n",
       "2                                 english, french, c++\n",
       "3                             english, german (poorly)\n",
       "4                                              english\n",
       "5                   english (fluently), chinese (okay)\n",
       "6                                              english\n",
       "7                              english, spanish (okay)\n",
       "8                                              english\n",
       "9                                   english (fluently)\n",
       "Name: speaks, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.speaks.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaks\n",
       "english                                                                                              21828\n",
       "english (fluently)                                                                                    6628\n",
       "english (fluently), spanish (poorly)                                                                  2059\n",
       "english (fluently), spanish (okay)                                                                    1917\n",
       "english (fluently), spanish (fluently)                                                                1288\n",
       "                                                                                                     ...  \n",
       "english (fluently), polish (fluently), french (poorly), hungarian (poorly), italian (poorly)             1\n",
       "english, spanish (fluently), hindi (okay), french (poorly)                                               1\n",
       "english (okay), spanish (okay), hebrew (okay)                                                            1\n",
       "english (fluently), slovenian (fluently), serbian (fluently), croatian (fluently), greek (poorly)        1\n",
       "english (fluently), russian (fluently), japanese (poorly), spanish (poorly), c++ (fluently)              1\n",
       "Name: count, Length: 7648, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.speaks.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For speaks we are going to try something different, while we could list all the different languages I feel capturing a person's english speaking ability would be a much more interesting attribute to have in our data. let's just check how many of our subjects actually speak english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59896"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(profiles['speaks']))\n",
    "speakeasy = profiles['speaks'].str.contains(r'english', case = False, na = False).sum()\n",
    "int(speakeasy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially it appears that 50 of our subjects don't speak any english, but with a little tweaking of the above function you can find that these subjects just have No language data. Which for now isn't that important, its just something to be aware of.\n",
    "\n",
    "Now lets try and isolate the english part of each subjects language ability (if we have it of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english\n",
       "[english]                                                                                               29889\n",
       "[english (fluently)]                                                                                    27970\n",
       "[english (okay)]                                                                                         1053\n",
       "[english (poorly)]                                                                                        592\n",
       "[english, english]                                                                                        115\n",
       "[english, english (fluently)]                                                                             114\n",
       "None                                                                                                       50\n",
       "[english (fluently), english (fluently)]                                                                   32\n",
       "[english (fluently), english]                                                                              30\n",
       "[english (fluently), english (poorly)]                                                                     23\n",
       "[english (fluently), english (okay), english (poorly)]                                                     13\n",
       "[english, english (okay)]                                                                                  13\n",
       "[english (okay), english (okay)]                                                                            7\n",
       "[english (fluently), english (okay)]                                                                        7\n",
       "[english, english (poorly)]                                                                                 5\n",
       "[english (fluently), english (fluently), english (fluently)]                                                4\n",
       "[english (okay), english (fluently)]                                                                        2\n",
       "[english (fluently), english (fluently), english (fluently), english (fluently), english (fluently)]        2\n",
       "[english (poorly), english (okay), english (fluently)]                                                      2\n",
       "[english (fluently), english (fluently), english (fluently), english (fluently), english]                   2\n",
       "[english (fluently), english (poorly), english (okay)]                                                      2\n",
       "[english (poorly), english (okay), english (fluently), english]                                             1\n",
       "[english (fluently), english (okay), english (poorly), english (fluently), english (poorly)]                1\n",
       "[english, english (fluently), english]                                                                      1\n",
       "[english (okay), english (poorly)]                                                                          1\n",
       "[english (fluently), english (fluently), english (okay)]                                                    1\n",
       "[english (fluently), english (okay), english (poorly), english (fluently), english (okay)]                  1\n",
       "[english, english (fluently), english (okay), english (poorly), english]                                    1\n",
       "[english (okay), english (poorly), english (fluently)]                                                      1\n",
       "[english (okay), english (fluently), english (poorly)]                                                      1\n",
       "[english (fluently), english (fluently), english (okay), english (poorly)]                                  1\n",
       "[english (fluently), english (poorly), english (poorly)]                                                    1\n",
       "[english, english (fluently), english (okay), english (poorly)]                                             1\n",
       "[english (poorly), english (okay), english (poorly)]                                                        1\n",
       "[english (okay), english (okay), english (okay)]                                                            1\n",
       "[english (okay), english]                                                                                   1\n",
       "[english (poorly), english (okay), english (fluently), english, english]                                    1\n",
       "[english (poorly), english (fluently)]                                                                      1\n",
       "[english, english, english]                                                                                 1\n",
       "[english (poorly), english (poorly), english (poorly), english (poorly), english (poorly)]                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles[\"english\"] = profiles.speaks.apply(lambda x: x.lower().split(\",\") if isinstance(x, str) else x) #turn each string into a list (luckily our languages are already comma-seperated)\n",
    "profiles['english'] = profiles.english.apply(lambda x: [entry.lstrip() for entry in x if 'english' in entry.lower()] if isinstance(x, list) else None)\n",
    "profiles['english'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like some of our entries put multiple levels of english in their languages. Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m current\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#profiles['english'] = profiles.english.apply(lambda x: [z.replace(\" \", \"\") for z in x] if isinstance(x, list) else None)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mprofiles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menglish\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_english\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_scale\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts(dropna \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\conor\\Desktop\\Coding\\Virtual_Environments\\envoid\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\conor\\Desktop\\Coding\\Virtual_Environments\\envoid\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\conor\\Desktop\\Coding\\Virtual_Environments\\envoid\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\conor\\Desktop\\Coding\\Virtual_Environments\\envoid\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\conor\\Desktop\\Coding\\Virtual_Environments\\envoid\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m current\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#profiles['english'] = profiles.english.apply(lambda x: [z.replace(\" \", \"\") for z in x] if isinstance(x, list) else None)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m profiles\u001b[38;5;241m.\u001b[39menglish\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: fix_english(x, english_scale) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m profiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts(dropna \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "english_scale = {'english (fluently)': 1, 'english': 2, 'english (okay)': 3, 'english (poorly)': 4} # create a string to hold my personal ranking of english fluency to handle multiple english entries.\n",
    "def fix_english(english_list:list, scale:dict):\n",
    "    current = english_list[0]\n",
    "    if len(english_list) > 1:\n",
    "        for i in range(1, len(english_list)):\n",
    "            if english_scale[current] > english_scale[english_list[i]]:\n",
    "                current = english_list[i]\n",
    "        return current\n",
    "    else:\n",
    "        return current\n",
    "\n",
    "#profiles['english'] = profiles.english.apply(lambda x: [z.replace(\" \", \"\") for z in x] if isinstance(x, list) else None)\n",
    "profiles['english'] = profiles.english.apply(lambda x: fix_english(x, english_scale) if len(x) != 0 and isinstance(x, list) else None)\n",
    "profiles['english'].value_counts(dropna = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's the english colomn sorted, looking a lot cleaner and a lot neater!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `offspring`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.offspring.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's keep things simple with this one and just refine it to those who have kids and those who do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kids_handler(x):\n",
    "    if isinstance(x, str):\n",
    "        result = x.split(\" kid\")[0]\n",
    "        if result == \"has a\":\n",
    "            return \"has\"\n",
    "        else:\n",
    "            return \"doesn't have\"\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.offspring = profiles.offspring.apply(lambda x: x.replace('&rsquo;', \"\\'\") if isinstance(x, str) else x)\n",
    "profiles['offspring'] = profiles.offspring.apply(lambda x: kids_handler(x))\n",
    "profiles.offspring.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying `diet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.diet.value_counts(dropna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diets = ['vegetarian', 'vegan', 'anything', 'kosher', 'halal', 'other']\n",
    "profiles['diet'] = profiles['diet'].apply(lambda x: replacer(diets, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.diet.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplification Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We still have a few of our old attributes to remove, these being: `education`, `ethnicity`, `pets`, `religion`, `sign` and `speaks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.drop(columns = ['education', 'ethnicity', 'pets', 'religion', 'sign','speaks'], inplace = True)\n",
    "profiles.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Next up is check which values have nulls and then handling them if they do in a way that is essentially up to my own discretion, however I try to use multiple techniques to handle nulls. \n",
    "\n",
    "If we check our columns we can see that theres a few rows that are 100% good to go on that front but beyond this we have a select few rows mainly on extraneous personal data that our users probably didn't want to or coulnd't be bothered to fill in.\n",
    "\n",
    "My Null Handling Methodology:\n",
    "\n",
    "1. Find how many values are missing + what percentage of the attribute is missing\n",
    "2. Try and find out why they might be missing (MCAR, MAR, MNAR)\n",
    "3. Implement a solution to the nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = profiles.isna().sum().sort_values()\n",
    "nulls[nulls > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCAR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "msno.heatmap(profiles, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing High Null Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame shape prior to removal: \", profiles.shape)\n",
    "profiles['null_count'] = profiles.isna().sum(axis = 1)\n",
    "profiles = profiles[profiles['null_count'] < (0.4 * profiles.shape[1])]\n",
    "profiles.drop(columns = ['null_count'], inplace = True)\n",
    "print(\"DataFrame shape post removal: \", profiles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `height` nulls\n",
    "\n",
    "`height` only has 2 null values so it's debatable if we should just get rid of them (it is only just 3 rows right?) This method is called **listwise deletion**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles[~profiles['height'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `english` Nulls\n",
    "\n",
    "`english` is also low enough to be handled by **listwise deletion**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles[~profiles['english'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `drinks` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['drinks'] = profiles['drinks'].fillna('rather not say')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `body_type` nulls\n",
    "\n",
    "All nulls in the body type column are replaced with average. This is done as the majority of people would have the average body type anyway.\n",
    "\n",
    "Note: Think about this assumption more critically.\n",
    "\n",
    "Note: This is an assumption, put it in the assumptions section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['body_type'] = profiles['body_type'].fillna('average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `smokes` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['smokes'] = profiles['smokes'].fillna('rather not say')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `ethnicity_1` and `ethnicity_2` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['ethnicity_1'] = profiles['ethnicity_1'].fillna('unspecified')\n",
    "profiles['ethnicity_2'] = profiles['ethnicity_2'].fillna('unspecified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `education_status` and `education level` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profiles.education_level.value_counts(dropna = False))\n",
    "profiles.education_status.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `job` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['job'] = profiles['job'].fillna('unspecified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `sign_sentiment` and `star_sign` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.drop(columns = ['sign_sentiment', 'star_sign'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `drugs` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['drugs'] = profiles['drugs'].fillna('unspecified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `dogs` and `cats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.drop(columns = ['dogs', 'cats'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `religous_sentiment` and `religous_preference` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['religious_sentiment'] = profiles['religious_sentiment'].fillna('not specified')\n",
    "profiles['religious_preference'] = profiles['religious_preference'].fillna('not specified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `diet` nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['diet'] = profiles['diet'].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.drop(columns = ['offspring'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers\n",
    "\n",
    "### Handling `age` outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.dtypes[profiles.dtypes == pd.Int64Dtype()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age is numerical so describe should give us a good idea of the distribution of the values (we already know the age column contains no nulls)\n",
    "profiles['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = profiles, x = 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ages above 100 are removed\n",
    "profiles = profiles[profiles[\"age\"] <= 100]\n",
    "profiles['age'].describe() #resulting distribution looks a lot more realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = profiles, x = 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `height` Outliers\n",
    "\n",
    "Next is handling height, and taking a look immediately at the results of the `.describe()` method we can see  a big problem. our min height is someone who claims to be one inch tall. Moving on to the box plot we can see that a few people are also claiming to have a height smaller than the smallest person in the world Chandra Bahadur Dangi who is 21.5 inches tall. So let's immediately remove these jokers from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = profiles, x = 'height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles[profiles[\"height\"] >= 40]\n",
    "profiles['height'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling `income` outliers\n",
    "\n",
    "One Thing we can notice about our income attributre is that most of our entries are in the category -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.income.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.loc[profiles['income'] == -1, 'income'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Inconsistent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.location.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body Type Variation\n",
    "\n",
    "As we can see most people on the site consider themselves to be either average or fit/athletic, you would expect this as most people with societaly dictated \"negative\" body type would not be confident enough to be on a dating website or less likely to report this feature of themselves accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['body_type'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My order is based on my own determination of a logical order for the available values for body_type based on my own perception of less fit to most fit\n",
    "my_order = ['rather not say', 'overweight', 'used up', 'curvy', 'full figured', 'a little extra', 'thin', 'skinny', 'average', 'fit', 'athletic', 'jacked']\n",
    "ax = sns.countplot(data = profiles, x = 'body_type', hue = 'body_type', order = my_order, hue_order = my_order)\n",
    "\n",
    "#Just wanted to put in the count values on top of each bar so as to better interpret the data for ease of interpretability. This is all done in 1000s points for fit.\n",
    "for axi in ax.patches:\n",
    "    height = axi.get_height()\n",
    "    ax.text(axi.get_x()+axi.get_width()/2.,\n",
    "            height + 3,\n",
    "            f'{round(axi.get_height() / 1000, 1)}K',\n",
    "            ha=\"center\")\n",
    "\n",
    "#rotate labels for no overlap     \n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Diet Nulls\n",
    "\n",
    "So when we look at the diet data we see that a wopping 68% of the data is NA so our users didnt specify diet data.\n",
    "\n",
    "It would be best to keep set nulls as a new category (\"not specified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### I FIND THIS INSUFFICIENT ######\n",
    "# Probably want to compare the distribution of missing values according to age (maybe other variables) and present values to see if this missingness is actually random \n",
    "profiles['diet'] = profiles['diet'].fillna('anything')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diet Variation\n",
    "\n",
    "Most people on the site expectedly have little to no dietary restriction or preference. Neglibile amounts of people on the dating site conform to religious diets (Maybe our site isn't that appealling to a religious audience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "profiles['diet'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6), dpi=80)\n",
    "\n",
    "ax = sns.countplot(data = profiles, x = 'diet', hue = 'diet')\n",
    "\n",
    "#Just wanted to put in the count values on top of each bar so as to better interpret the data for ease of interpretability. This is all done in 1000s points for fit.\n",
    "for axi in ax.patches:\n",
    "    height = axi.get_height()\n",
    "    ax.text(axi.get_x()+axi.get_width()/2.,\n",
    "            height + 3,\n",
    "            f'{round(axi.get_height() / 1000, 1)}K',\n",
    "            ha=\"center\")\n",
    "\n",
    "#rotate labels for no overlap     \n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45, ha = \"right\", x = -0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Handling Drinks and Drugs Nulls\n",
    "\n",
    "So we have a few missing drugs and less amount of missing drinks. This would be a good time to test if people are just leaving the field empty for personal reasons or is it just random?\n",
    "\n",
    "From looking at the p values of the prevalence of drinks and drugs with other factors such as age, sex, income, edication and religion. \n",
    "\n",
    "1. We can see that people with certain religious beliefs are likely to skip drug related questions and to a lesser extent drink related questions.\n",
    "2. Socioeconomic and demograpgic factors influence response rates for these attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_square_missing(profiles, missing_col, categorical_col): # < 0.05 returned suggests MAR\n",
    "    profiles_copy = profiles.copy()\n",
    "    profiles_copy['missing'] = profiles_copy[missing_col].isna().astype(int)\n",
    "\n",
    "    contingency_table = pd.crosstab(profiles_copy['missing'], profiles_copy[categorical_col])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    return p\n",
    "\n",
    "for col in ['age', 'sex', 'education', 'income', 'religion']:\n",
    "    p_value = chi_square_missing(profiles, 'drugs', col)\n",
    "    print(f\"Missingness in drugs vs. {col}: p-value = {p_value}\")\n",
    "\n",
    "    p_value = chi_square_missing(profiles, 'drinks', col)\n",
    "    print(f\"Missingness in drinks vs. {col}: p-value = {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drink and Drugs Variation\n",
    "\n",
    "While the drinks attribute has a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profiles['drugs'].value_counts(dropna = False), \"\\n\")\n",
    "print(profiles['drinks'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data = profiles[profiles['drugs'] != 'never'], x = 'drinks', hue = 'drugs', )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education Variation\n",
    "\n",
    "This attribute is need of serious cleaning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_desc = profiles['education'].describe()\n",
    "print(edu_desc)\n",
    "profiles['education'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envoid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
